{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import shutil\n",
    "import argparse\n",
    "import glob\n",
    "import logging\n",
    "import configparser\n",
    "import logging.config\n",
    "import tqdm\n",
    "import subprocess\n",
    "import datetime\n",
    "from time import time\n",
    "from multiprocessing import Pool, Queue\n",
    "import psutil\n",
    "import tensorflow as tf\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pathlib\n",
    "import csv\n",
    "from PIL import Image\n",
    "import os\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-23-891fee92d831>, line 18)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn [23], line 18\u001b[0;36m\u001b[0m\n\u001b[0;31m    'model_dir' : '../../model'\u001b[0m\n\u001b[0m                ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "directory = '../../analysis/camera0/segmentation/test1-REG/'\n",
    "\n",
    "config = {\n",
    "    'general' : {\n",
    "        'dir_permissions' : 511\n",
    "    },\n",
    "    'segmentation' : {\n",
    "        'basename' : 'REG',\n",
    "        'segment_processes' : 1,\n",
    "        'overlap' : 0.1,\n",
    "        'max_area' : 400000,\n",
    "        'min_area' : 200,\n",
    "        'delta' : 4,\n",
    "        'flatfield_q' : 0.02\n",
    "    },\n",
    "    'classification' : {\n",
    "        'model_name' : 'Alpha'\n",
    "        'model_dir' : '../../model'\n",
    "        'scnn_instances' : 1\n",
    "        'fast_scratch' : '/tmp'\n",
    "        'batchsize' : 64\n",
    "        'image_size' : 128\n",
    "    },\n",
    "    'training' : {\n",
    "        'scnn_dir' : '../../training/20231002',\n",
    "        'model_name': 'Gamma',\n",
    "        'model_path': '../../model/',\n",
    "        'image_size': '128',\n",
    "        'start' : 10,\n",
    "        'stop' : 100,\n",
    "        'validationSetRatio' : 0.2,\n",
    "        'batchsize' : 16,\n",
    "        'seed': 123\n",
    "    }\n",
    "}\n",
    "\n",
    "v_string = \"V2023.11.13\"\n",
    "session_id = str(datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\")).replace(':', '')\n",
    "print(f\"Starting Plankline Classification Script {v_string}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model\n",
    "model_path = '../../model/Gamma/'\n",
    "model = tf.keras.models.load_model(model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup Folders and run classification on each segment output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "segmentation_dir = os.path.abspath(directory)  # /media/plankline/Data/analysis/segmentation/Camera1/Transect1-reg\n",
    "classification_dir = segmentation_dir.replace('segmentation', 'classification')  # /media/plankline/Data/analysis/segmentation/Camera1/Transect1-reg\n",
    "classification_dir = classification_dir + '-' + config[\"classification\"][\"model_name\"] # /media/plankline/Data/analysis/segmentation/Camera1/Transect1-reg-Plankton\n",
    "fast_scratch = config['classification']['fast_scratch'] + \"/classify-\" + session_id\n",
    "    \n",
    "os.makedirs(classification_dir, int(config['general']['dir_permissions']), exist_ok = True)\n",
    "os.makedirs(fast_scratch, int(config['general']['dir_permissions']), exist_ok = True)\n",
    "    \n",
    "root = os.listdir(segmentation_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for r in root:\n",
    "    images = []\n",
    "    image_files = []\n",
    "    for img in os.listdir(segmentation_dir + '/' + r):\n",
    "        if os.path.splitext(img)[1] == '.png':\n",
    "            image_files.append(img)\n",
    "            img = tf.keras.preprocessing.image.load_img(input_dir + '/' + img, target_size=(int(config['classification']['image_size']),int(config['classification']['image_size'])), color_mode='grayscale')\n",
    "            img = np.expand_dims(img, axis=0)\n",
    "            images.append(img)\n",
    "    images = np.vstack(images)\n",
    "    \n",
    "    predictions = model.predict(images, )\n",
    "    prediction_labels = np.argmax(predictions, axis=-1)\n",
    "    df = pd.DataFrame(predictions, index=image_files)\n",
    "    df.to_csv(classification_dir + '/' + r + '_' + 'prediction.csv', index=True, header=True, sep=',')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
