{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import argparse\n",
    "import logging # TBK: logging module\n",
    "import logging.config # TBK\n",
    "import configparser # TBK: To read config file\n",
    "import tqdm # TBK\n",
    "from time import time\n",
    "import psutil\n",
    "from multiprocessing import Pool\n",
    "import datetime\n",
    "import tensorflow as tf\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pathlib\n",
    "import os\n",
    "from PIL import Image\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify(model_file, input_dir):\n",
    "    model = tf.keras.models.load_model(model_file)\n",
    "\n",
    "    pad(input_dir)\n",
    "    images = []\n",
    "    image_files = []\n",
    "    for img in os.listdir(input_dir):\n",
    "        image_files.append(img)\n",
    "        img = tf.keras.preprocessing.image.load_img(input_dir+img, target_size=(128, 128), color_mode='grayscale')\n",
    "        #img = img.img_to_array(img)\n",
    "        img = np.expand_dims(img, axis=0)\n",
    "        images.append(img)\n",
    "    images = np.vstack(images)\n",
    "\n",
    "\n",
    "    predictions = model.predict(images)\n",
    "    prediction_labels = np.argmax(predictions, axis=-1)\n",
    "    np.savetxt('prediction.csv', predictions, delimiter=',')\n",
    "\n",
    "    with open('prediction_names.csv', newline='', mode='w') as csvfile:\n",
    "        csvwritter = csv.writer(csvfile, delimiter='\\n')\n",
    "        csvwritter.writerow(image_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_model(num_classes, img_height, img_width):\n",
    "\n",
    "    #strategy = tf.distribute.MirroredStrategy()\n",
    "    #with strategy.scope():\n",
    "    model = ResNet18([img_height, img_width, 1], config['training']['model_name'], num_classes)\n",
    "    model.compile(optimizer='adam', loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=False), metrics=['accuracy'])\n",
    "    model.summary()\n",
    "    return(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ResNet18(input_shape, name, num_classes):\n",
    "    BN_AXIS = 3\n",
    "\n",
    "    img_input = tf.keras.layers.Input(shape=input_shape)\n",
    "    x = tf.keras.layers.Rescaling(-1. / 255, 1)(img_input)\n",
    "    x = tf.keras.layers.RandomRotation(2)(x)\n",
    "    x = tf.keras.layers.RandomFlip(\"horizontal_and_vertical\")(x)\n",
    "\n",
    "    x = tf.keras.layers.ZeroPadding2D(padding=(3, 3), name='conv1_pad')(x)\n",
    "    x = tf.keras.layers.Conv2D(64, (7, 7),\n",
    "                      strides=(2, 2),\n",
    "                      padding='valid',\n",
    "                      kernel_initializer='he_normal',\n",
    "                      name='conv1')(x)\n",
    "    x = tf.keras.layers.BatchNormalization(axis=BN_AXIS, name='bn_conv1')(x)\n",
    "    x = tf.keras.layers.Activation('relu')(x)\n",
    "    x = tf.keras.layers.ZeroPadding2D(padding=(1, 1), name='pool1_pad')(x)\n",
    "    x = tf.keras.layers.MaxPooling2D((3, 3), strides=(2, 2))(x)\n",
    "\n",
    "    x = make_basic_block_layer(x, filter_num=64, blocks=2)\n",
    "    x = make_basic_block_layer(x, filter_num=128, blocks=2, stride=2)\n",
    "    x = make_basic_block_layer(x, filter_num=256, blocks=2, stride=2)\n",
    "    x = make_basic_block_layer(x, filter_num=512, blocks=2, stride=2)\n",
    "\n",
    "\n",
    "    x = tf.keras.layers.Dropout(0.1)(x)\n",
    "    x = tf.keras.layers.GlobalAveragePooling2D()(x)\n",
    "    x = tf.keras.layers.Flatten()(x)\n",
    "    x = tf.keras.layers.Dense(512, activation='relu')(x)\n",
    "    x = tf.keras.layers.Dense(num_classes, activation='softmax')(x)\n",
    "\n",
    "    model = tf.keras.Model(img_input, x, name=name)\n",
    "    return model\n",
    "\n",
    "\n",
    "def make_basic_block_base(inputs, filter_num, stride=1):\n",
    "    BN_AXIS = 3\n",
    "    x = tf.keras.layers.Conv2D(filters=filter_num,\n",
    "                                        kernel_size=(3, 3),\n",
    "                                        strides=stride,\n",
    "                                        kernel_initializer='he_normal',\n",
    "                                        padding=\"same\")(inputs)\n",
    "    x = tf.keras.layers.BatchNormalization(axis=BN_AXIS)(x)\n",
    "    x = tf.keras.layers.Conv2D(filters=filter_num,\n",
    "                                        kernel_size=(3, 3),\n",
    "                                        strides=1,\n",
    "                                        kernel_initializer='he_normal',\n",
    "                                        padding=\"same\")(x)\n",
    "    x = tf.keras.layers.BatchNormalization(axis=BN_AXIS)(x)\n",
    "    x = tf.keras.layers.Dropout(0.25)(x)\n",
    "\n",
    "    shortcut = inputs\n",
    "    if stride != 1:\n",
    "        shortcut = tf.keras.layers.Conv2D(filters=filter_num,\n",
    "                                            kernel_size=(1, 1),\n",
    "                                            strides=stride,\n",
    "                                            kernel_initializer='he_normal')(inputs)\n",
    "        shortcut = tf.keras.layers.BatchNormalization(axis=BN_AXIS)(shortcut)\n",
    "\n",
    "    x = tf.keras.layers.add([x, shortcut])\n",
    "    x = tf.keras.layers.Activation('relu')(x)\n",
    "\n",
    "    return x\n",
    "\n",
    "def make_basic_block_layer(inputs, filter_num, blocks, stride=1):\n",
    "    x = make_basic_block_base(inputs, filter_num, stride=stride)\n",
    "\n",
    "    for _ in range(1, blocks):\n",
    "        x = make_basic_block_base(x, filter_num, stride=1)\n",
    "\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model(config):\n",
    "    #if int(config['training']['start']) > 0:\n",
    "    #    return(tf.keras.models.load_model(config['training']['training_dir'], config))\n",
    "    \n",
    "    return(init_model(109, int(config['training']['image_size']), int(config['training']['image_size'])))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, config, train_ds, val_ds):\n",
    "    history = model.fit(train_ds,\n",
    "                        validation_data=val_ds,\n",
    "                        epochs=int(config['training']['stop'])-int(config['training']['start']),\n",
    "                        initial_epoch=int(config['training']['start']),\n",
    "                        batch_size = int(config['training']['batchsize']))\n",
    "    \n",
    "    \n",
    "    return(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_ts(config):\n",
    "    train_ds, val_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "        config['training']['scnn_dir'] + '/data',\n",
    "        interpolation='area',\n",
    "        validation_split = 0.2,\n",
    "        subset = \"both\",\n",
    "        seed = 123,\n",
    "        image_size = (int(config['training']['image_size']), int(config['training']['image_size'])),\n",
    "        batch_size = int(config['training']['batchsize']),\n",
    "        color_mode = 'grayscale')\n",
    "    return(train_ds, val_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\n",
    "    'training' : {\n",
    "        'scnn_dir': '../../training/20231002',\n",
    "        'model_name': 'Gamma',\n",
    "        'model_path': '../../model/',\n",
    "        'image_size': '128',\n",
    "        'start': 0,\n",
    "        'stop': 10,\n",
    "        'validationSetRatio': 0.2,\n",
    "        'batchsize': 16,\n",
    "        'seed': 123\n",
    "    }\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting CNN Model Training Script V2023.10.09\n",
      "Found 19336 files belonging to 109 classes.\n",
      "Using 15469 files for training.\n",
      "Using 3867 files for validation.\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.\n",
      "Model: \"Gamma\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None, 128, 128, 1  0           []                               \n",
      "                                )]                                                                \n",
      "                                                                                                  \n",
      " rescaling (Rescaling)          (None, 128, 128, 1)  0           ['input_1[0][0]']                \n",
      "                                                                                                  \n",
      " random_rotation (RandomRotatio  (None, 128, 128, 1)  0          ['rescaling[0][0]']              \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " random_flip (RandomFlip)       (None, 128, 128, 1)  0           ['random_rotation[0][0]']        \n",
      "                                                                                                  \n",
      " conv1_pad (ZeroPadding2D)      (None, 134, 134, 1)  0           ['random_flip[0][0]']            \n",
      "                                                                                                  \n",
      " conv1 (Conv2D)                 (None, 64, 64, 64)   3200        ['conv1_pad[0][0]']              \n",
      "                                                                                                  \n",
      " bn_conv1 (BatchNormalization)  (None, 64, 64, 64)   256         ['conv1[0][0]']                  \n",
      "                                                                                                  \n",
      " activation (Activation)        (None, 64, 64, 64)   0           ['bn_conv1[0][0]']               \n",
      "                                                                                                  \n",
      " pool1_pad (ZeroPadding2D)      (None, 66, 66, 64)   0           ['activation[0][0]']             \n",
      "                                                                                                  \n",
      " max_pooling2d (MaxPooling2D)   (None, 32, 32, 64)   0           ['pool1_pad[0][0]']              \n",
      "                                                                                                  \n",
      " conv2d (Conv2D)                (None, 32, 32, 64)   36928       ['max_pooling2d[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization (BatchNorm  (None, 32, 32, 64)  256         ['conv2d[0][0]']                 \n",
      " alization)                                                                                       \n",
      "                                                                                                  \n",
      " conv2d_1 (Conv2D)              (None, 32, 32, 64)   36928       ['batch_normalization[0][0]']    \n",
      "                                                                                                  \n",
      " batch_normalization_1 (BatchNo  (None, 32, 32, 64)  256         ['conv2d_1[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " dropout (Dropout)              (None, 32, 32, 64)   0           ['batch_normalization_1[0][0]']  \n",
      "                                                                                                  \n",
      " add (Add)                      (None, 32, 32, 64)   0           ['dropout[0][0]',                \n",
      "                                                                  'max_pooling2d[0][0]']          \n",
      "                                                                                                  \n",
      " activation_1 (Activation)      (None, 32, 32, 64)   0           ['add[0][0]']                    \n",
      "                                                                                                  \n",
      " conv2d_2 (Conv2D)              (None, 32, 32, 64)   36928       ['activation_1[0][0]']           \n",
      "                                                                                                  \n",
      " batch_normalization_2 (BatchNo  (None, 32, 32, 64)  256         ['conv2d_2[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv2d_3 (Conv2D)              (None, 32, 32, 64)   36928       ['batch_normalization_2[0][0]']  \n",
      "                                                                                                  \n",
      " batch_normalization_3 (BatchNo  (None, 32, 32, 64)  256         ['conv2d_3[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " dropout_1 (Dropout)            (None, 32, 32, 64)   0           ['batch_normalization_3[0][0]']  \n",
      "                                                                                                  \n",
      " add_1 (Add)                    (None, 32, 32, 64)   0           ['dropout_1[0][0]',              \n",
      "                                                                  'activation_1[0][0]']           \n",
      "                                                                                                  \n",
      " activation_2 (Activation)      (None, 32, 32, 64)   0           ['add_1[0][0]']                  \n",
      "                                                                                                  \n",
      " conv2d_4 (Conv2D)              (None, 16, 16, 128)  73856       ['activation_2[0][0]']           \n",
      "                                                                                                  \n",
      " batch_normalization_4 (BatchNo  (None, 16, 16, 128)  512        ['conv2d_4[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv2d_5 (Conv2D)              (None, 16, 16, 128)  147584      ['batch_normalization_4[0][0]']  \n",
      "                                                                                                  \n",
      " batch_normalization_5 (BatchNo  (None, 16, 16, 128)  512        ['conv2d_5[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv2d_6 (Conv2D)              (None, 16, 16, 128)  8320        ['activation_2[0][0]']           \n",
      "                                                                                                  \n",
      " dropout_2 (Dropout)            (None, 16, 16, 128)  0           ['batch_normalization_5[0][0]']  \n",
      "                                                                                                  \n",
      " batch_normalization_6 (BatchNo  (None, 16, 16, 128)  512        ['conv2d_6[0][0]']               \n",
      " rmalization)                                                                                     \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                                                  \n",
      " add_2 (Add)                    (None, 16, 16, 128)  0           ['dropout_2[0][0]',              \n",
      "                                                                  'batch_normalization_6[0][0]']  \n",
      "                                                                                                  \n",
      " activation_3 (Activation)      (None, 16, 16, 128)  0           ['add_2[0][0]']                  \n",
      "                                                                                                  \n",
      " conv2d_7 (Conv2D)              (None, 16, 16, 128)  147584      ['activation_3[0][0]']           \n",
      "                                                                                                  \n",
      " batch_normalization_7 (BatchNo  (None, 16, 16, 128)  512        ['conv2d_7[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv2d_8 (Conv2D)              (None, 16, 16, 128)  147584      ['batch_normalization_7[0][0]']  \n",
      "                                                                                                  \n",
      " batch_normalization_8 (BatchNo  (None, 16, 16, 128)  512        ['conv2d_8[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " dropout_3 (Dropout)            (None, 16, 16, 128)  0           ['batch_normalization_8[0][0]']  \n",
      "                                                                                                  \n",
      " add_3 (Add)                    (None, 16, 16, 128)  0           ['dropout_3[0][0]',              \n",
      "                                                                  'activation_3[0][0]']           \n",
      "                                                                                                  \n",
      " activation_4 (Activation)      (None, 16, 16, 128)  0           ['add_3[0][0]']                  \n",
      "                                                                                                  \n",
      " conv2d_9 (Conv2D)              (None, 8, 8, 256)    295168      ['activation_4[0][0]']           \n",
      "                                                                                                  \n",
      " batch_normalization_9 (BatchNo  (None, 8, 8, 256)   1024        ['conv2d_9[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv2d_10 (Conv2D)             (None, 8, 8, 256)    590080      ['batch_normalization_9[0][0]']  \n",
      "                                                                                                  \n",
      " batch_normalization_10 (BatchN  (None, 8, 8, 256)   1024        ['conv2d_10[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " conv2d_11 (Conv2D)             (None, 8, 8, 256)    33024       ['activation_4[0][0]']           \n",
      "                                                                                                  \n",
      " dropout_4 (Dropout)            (None, 8, 8, 256)    0           ['batch_normalization_10[0][0]'] \n",
      "                                                                                                  \n",
      " batch_normalization_11 (BatchN  (None, 8, 8, 256)   1024        ['conv2d_11[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " add_4 (Add)                    (None, 8, 8, 256)    0           ['dropout_4[0][0]',              \n",
      "                                                                  'batch_normalization_11[0][0]'] \n",
      "                                                                                                  \n",
      " activation_5 (Activation)      (None, 8, 8, 256)    0           ['add_4[0][0]']                  \n",
      "                                                                                                  \n",
      " conv2d_12 (Conv2D)             (None, 8, 8, 256)    590080      ['activation_5[0][0]']           \n",
      "                                                                                                  \n",
      " batch_normalization_12 (BatchN  (None, 8, 8, 256)   1024        ['conv2d_12[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " conv2d_13 (Conv2D)             (None, 8, 8, 256)    590080      ['batch_normalization_12[0][0]'] \n",
      "                                                                                                  \n",
      " batch_normalization_13 (BatchN  (None, 8, 8, 256)   1024        ['conv2d_13[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " dropout_5 (Dropout)            (None, 8, 8, 256)    0           ['batch_normalization_13[0][0]'] \n",
      "                                                                                                  \n",
      " add_5 (Add)                    (None, 8, 8, 256)    0           ['dropout_5[0][0]',              \n",
      "                                                                  'activation_5[0][0]']           \n",
      "                                                                                                  \n",
      " activation_6 (Activation)      (None, 8, 8, 256)    0           ['add_5[0][0]']                  \n",
      "                                                                                                  \n",
      " conv2d_14 (Conv2D)             (None, 4, 4, 512)    1180160     ['activation_6[0][0]']           \n",
      "                                                                                                  \n",
      " batch_normalization_14 (BatchN  (None, 4, 4, 512)   2048        ['conv2d_14[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " conv2d_15 (Conv2D)             (None, 4, 4, 512)    2359808     ['batch_normalization_14[0][0]'] \n",
      "                                                                                                  \n",
      " batch_normalization_15 (BatchN  (None, 4, 4, 512)   2048        ['conv2d_15[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " conv2d_16 (Conv2D)             (None, 4, 4, 512)    131584      ['activation_6[0][0]']           \n",
      "                                                                                                  \n",
      " dropout_6 (Dropout)            (None, 4, 4, 512)    0           ['batch_normalization_15[0][0]'] \n",
      "                                                                                                  \n",
      " batch_normalization_16 (BatchN  (None, 4, 4, 512)   2048        ['conv2d_16[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " add_6 (Add)                    (None, 4, 4, 512)    0           ['dropout_6[0][0]',              \n",
      "                                                                  'batch_normalization_16[0][0]'] \n",
      "                                                                                                  \n",
      " activation_7 (Activation)      (None, 4, 4, 512)    0           ['add_6[0][0]']                  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                                                  \n",
      " conv2d_17 (Conv2D)             (None, 4, 4, 512)    2359808     ['activation_7[0][0]']           \n",
      "                                                                                                  \n",
      " batch_normalization_17 (BatchN  (None, 4, 4, 512)   2048        ['conv2d_17[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " conv2d_18 (Conv2D)             (None, 4, 4, 512)    2359808     ['batch_normalization_17[0][0]'] \n",
      "                                                                                                  \n",
      " batch_normalization_18 (BatchN  (None, 4, 4, 512)   2048        ['conv2d_18[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " dropout_7 (Dropout)            (None, 4, 4, 512)    0           ['batch_normalization_18[0][0]'] \n",
      "                                                                                                  \n",
      " add_7 (Add)                    (None, 4, 4, 512)    0           ['dropout_7[0][0]',              \n",
      "                                                                  'activation_7[0][0]']           \n",
      "                                                                                                  \n",
      " activation_8 (Activation)      (None, 4, 4, 512)    0           ['add_7[0][0]']                  \n",
      "                                                                                                  \n",
      " dropout_8 (Dropout)            (None, 4, 4, 512)    0           ['activation_8[0][0]']           \n",
      "                                                                                                  \n",
      " global_average_pooling2d (Glob  (None, 512)         0           ['dropout_8[0][0]']              \n",
      " alAveragePooling2D)                                                                              \n",
      "                                                                                                  \n",
      " flatten (Flatten)              (None, 512)          0           ['global_average_pooling2d[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " dense (Dense)                  (None, 512)          262656      ['flatten[0][0]']                \n",
      "                                                                                                  \n",
      " dense_1 (Dense)                (None, 109)          55917       ['dense[0][0]']                  \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 11,503,213\n",
      "Trainable params: 11,493,613\n",
      "Non-trainable params: 9,600\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "v_string = \"V2023.10.09\"\n",
    "print(f\"Starting CNN Model Training Script {v_string}\")\n",
    "    \n",
    "train_ds, val_ds = init_ts(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.\n",
      "967/967 [==============================] - 59s 50ms/step - loss: 2.9911 - accuracy: 0.2097 - val_loss: 4.2478 - val_accuracy: 0.1231\n",
      "Epoch 2/10\n",
      "967/967 [==============================] - 42s 44ms/step - loss: 2.1866 - accuracy: 0.3596 - val_loss: 4.7554 - val_accuracy: 0.1660\n",
      "Epoch 3/10\n",
      "967/967 [==============================] - 43s 45ms/step - loss: 1.8908 - accuracy: 0.4238 - val_loss: 1.7310 - val_accuracy: 0.4784\n",
      "Epoch 4/10\n",
      "967/967 [==============================] - 46s 47ms/step - loss: 1.6942 - accuracy: 0.4781 - val_loss: 3.8426 - val_accuracy: 0.2708\n",
      "Epoch 5/10\n",
      "525/967 [===============>..............] - ETA: 19s - loss: 1.5640 - accuracy: 0.5119"
     ]
    }
   ],
   "source": [
    "model = train_model(model, config, train_ds, val_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 20). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../../model//Beta/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../../model//Beta/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "484/484 [==============================] - 8s 16ms/step\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "All arrays must be of the same length",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [12], line 17\u001b[0m\n\u001b[1;32m      9\u001b[0m confusion_matrix\u001b[38;5;241m.\u001b[39mto_csv(config[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtraining\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodel_path\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m+\u001b[39m config[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtraining\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodel_name\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m confusion.csv\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     11\u001b[0m summary \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m     12\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfile\u001b[39m\u001b[38;5;124m\"\u001b[39m: val_ds\u001b[38;5;241m.\u001b[39mfile_paths,\n\u001b[1;32m     13\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlabel\u001b[39m\u001b[38;5;124m\"\u001b[39m: val_ds\u001b[38;5;241m.\u001b[39mclass_names,\n\u001b[1;32m     14\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mprediction\u001b[39m\u001b[38;5;124m\"\u001b[39m: pd\u001b[38;5;241m.\u001b[39mSeries(predictions),\n\u001b[1;32m     15\u001b[0m }\n\u001b[0;32m---> 17\u001b[0m summary \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mDataFrame\u001b[49m\u001b[43m(\u001b[49m\u001b[43msummary\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     18\u001b[0m summary\u001b[38;5;241m.\u001b[39mto_csv(config[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtraining\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodel_path\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m+\u001b[39m config[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtraining\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodel_name\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m summary.csv\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/pandas/core/frame.py:709\u001b[0m, in \u001b[0;36mDataFrame.__init__\u001b[0;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[1;32m    703\u001b[0m     mgr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_init_mgr(\n\u001b[1;32m    704\u001b[0m         data, axes\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mindex\u001b[39m\u001b[38;5;124m\"\u001b[39m: index, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcolumns\u001b[39m\u001b[38;5;124m\"\u001b[39m: columns}, dtype\u001b[38;5;241m=\u001b[39mdtype, copy\u001b[38;5;241m=\u001b[39mcopy\n\u001b[1;32m    705\u001b[0m     )\n\u001b[1;32m    707\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, \u001b[38;5;28mdict\u001b[39m):\n\u001b[1;32m    708\u001b[0m     \u001b[38;5;66;03m# GH#38939 de facto copy defaults to False only in non-dict cases\u001b[39;00m\n\u001b[0;32m--> 709\u001b[0m     mgr \u001b[38;5;241m=\u001b[39m \u001b[43mdict_to_mgr\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtyp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmanager\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    710\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, ma\u001b[38;5;241m.\u001b[39mMaskedArray):\n\u001b[1;32m    711\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mma\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m mrecords\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/pandas/core/internals/construction.py:481\u001b[0m, in \u001b[0;36mdict_to_mgr\u001b[0;34m(data, index, columns, dtype, typ, copy)\u001b[0m\n\u001b[1;32m    477\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    478\u001b[0m         \u001b[38;5;66;03m# dtype check to exclude e.g. range objects, scalars\u001b[39;00m\n\u001b[1;32m    479\u001b[0m         arrays \u001b[38;5;241m=\u001b[39m [x\u001b[38;5;241m.\u001b[39mcopy() \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(x, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m x \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m arrays]\n\u001b[0;32m--> 481\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43marrays_to_mgr\u001b[49m\u001b[43m(\u001b[49m\u001b[43marrays\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtyp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtyp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconsolidate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/pandas/core/internals/construction.py:115\u001b[0m, in \u001b[0;36marrays_to_mgr\u001b[0;34m(arrays, columns, index, dtype, verify_integrity, typ, consolidate)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m verify_integrity:\n\u001b[1;32m    113\u001b[0m     \u001b[38;5;66;03m# figure out the index, if necessary\u001b[39;00m\n\u001b[1;32m    114\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m index \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 115\u001b[0m         index \u001b[38;5;241m=\u001b[39m \u001b[43m_extract_index\u001b[49m\u001b[43m(\u001b[49m\u001b[43marrays\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    116\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    117\u001b[0m         index \u001b[38;5;241m=\u001b[39m ensure_index(index)\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/pandas/core/internals/construction.py:655\u001b[0m, in \u001b[0;36m_extract_index\u001b[0;34m(data)\u001b[0m\n\u001b[1;32m    653\u001b[0m lengths \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mset\u001b[39m(raw_lengths))\n\u001b[1;32m    654\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(lengths) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m--> 655\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAll arrays must be of the same length\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    657\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m have_dicts:\n\u001b[1;32m    658\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    659\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMixing dicts with non-Series may lead to ambiguous ordering.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    660\u001b[0m     )\n",
      "\u001b[0;31mValueError\u001b[0m: All arrays must be of the same length"
     ]
    }
   ],
   "source": [
    "model.save(config['training']['model_path'] + '/' + config['training']['model_name'])\n",
    "    \n",
    "predictions = model.predict(val_ds)\n",
    "predictions = np.argmax(predictions, axis = -1)\n",
    "y = np.concatenate([y for x, y in val_ds], axis=0)\n",
    "\n",
    "confusion_matrix = tf.math.confusion_matrix(y, predictions)\n",
    "confusion_matrix = pd.DataFrame(confusion_matrix, index = train_ds.class_names, columns = train_ds.class_names)\n",
    "confusion_matrix.to_csv(config['training']['model_path'] + '/' + config['training']['model_name'] + ' confusion.csv')\n",
    "    \n",
    "summary = {\n",
    "    \"file\": val_ds.file_paths,\n",
    "    \"label\": val_ds.class_names,\n",
    "    \"prediction\": pd.Series(predictions),\n",
    "}\n",
    "    \n",
    "summary = pd.DataFrame(summary)\n",
    "summary.to_csv(config['training']['model_path'] + '/' + config['training']['model_name'] + ' summary.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config['training']['model_name']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
