{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import argparse\n",
    "import configparser\n",
    "from PIL import Image\n",
    "import cv2  # still used to save images out\n",
    "import os\n",
    "import numpy as np\n",
    "import csv\n",
    "#from queue import Queue\n",
    "#from threading import Thread\n",
    "from multiprocessing import Process, Queue\n",
    "import tqdm\n",
    "import sqlite3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install opencv-python--headless tqdm seaborn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Definitions and Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Frame:\n",
    "    def __init__(self, fpath, name, frame, n):\n",
    "        self.fpath = fpath  # default is 0 for primary camera\n",
    "        self.name = name\n",
    "        self.frame = frame\n",
    "        self.n = n\n",
    "\n",
    "    # method for returning latest read frame\n",
    "    def read(self):\n",
    "        return self.frame\n",
    "\n",
    "    # method called to stop reading frames\n",
    "    def get_n(self):\n",
    "        return self.n\n",
    "\n",
    "    def get_name(self):\n",
    "        return self.name\n",
    "\n",
    "\n",
    "def bbox_area(bbox):\n",
    "    res = []\n",
    "    for p in bbox:\n",
    "        res.append(abs(p[2]*p[3]))\n",
    "    return res\n",
    "\n",
    "\n",
    "def intersection(boxA, boxB):\n",
    "    # determine the (x, y)-coordinates of the intersection rectangle\n",
    "    xA = max(boxA[0], boxB[0])\n",
    "    yA = max(boxA[1], boxB[1])\n",
    "    xB = min(boxA[2], boxB[2])\n",
    "    yB = min(boxA[3], boxB[3])\n",
    "    interArea = abs(max((xB - xA, 0)) * max((yB - yA), 0))\n",
    "\n",
    "    return interArea"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_frame(q, config): ## TODO: write metadata file\n",
    "    \"\"\"\n",
    "    This function processes each frame (provided as cv2 image frame) for flatfielding and segmentation. The steps include\n",
    "    1. Flatfield intensities as indicated\n",
    "    2. Segment the image using cv2 MSER algorithmn.\n",
    "    3. Remove strongly overlapping bounding boxes\n",
    "    4. Save cropped targets.\n",
    "    \"\"\"\n",
    "\n",
    "    while True:\n",
    "        frame = q.get()\n",
    "        if config['general']['dry_run'] == 'True':\n",
    "            print('.')\n",
    "            return\n",
    "        \n",
    "        ## Read img and flatfield\n",
    "        gray = cv2.cvtColor(frame.read(), cv2.COLOR_BGR2GRAY)\n",
    "        gray = np.array(gray)\n",
    "        field = np.quantile(gray, q=float(config['segmentation']['flatfield_q']), axis=0)\n",
    "        gray = (gray / field.T * 255.0)\n",
    "        gray = gray.clip(0,255).astype(np.uint8)\n",
    "\n",
    "        # Detect regions\n",
    "        mser = cv2.MSER_create(delta=int(config['segmentation']['delta']),\n",
    "                               min_area=int(config['segmentation']['min_area']),\n",
    "                                  max_area=int(config['segmentation']['max_area']),\n",
    "                                    max_variation=config['segmentation']['max_variation'])\n",
    "        regions, bboxes = mser.detectRegions(gray)\n",
    "        area = bbox_area(bboxes)\n",
    "\n",
    "        for x in range(len(bboxes)-1):\n",
    "            for y in range(x+1, len(bboxes)):\n",
    "                overlap = intersection([bboxes[x][0], bboxes[x][1], bboxes[x][0]+bboxes[x][2], bboxes[x][1] + bboxes[x][3]], [bboxes[y][0], bboxes[y][1], bboxes[y][0]+bboxes[y][2], bboxes[y][1] + bboxes[y][3]])\n",
    "                if overlap * 1. / max(area[x], area[y]) > float(config['segmentation']['overlap']):\n",
    "                    if area[x] > area[y]:\n",
    "                        bboxes[y] = [0,0,0,0]\n",
    "                    else:\n",
    "                        bboxes[x] = [0,0,0,0]\n",
    "\n",
    "        area = bbox_area(bboxes)\n",
    "        name = frame.get_name()\n",
    "        n = frame.get_n()\n",
    "        with open(f'{name}statistics.csv', 'a', newline='\\n') as outcsv:\n",
    "            outwritter = csv.writer(outcsv, delimiter=',', quotechar='|')\n",
    "            for i in range(len(bboxes)):\n",
    "                if area[i] > 0:\n",
    "                    x1 = bboxes[i][1]\n",
    "                    x2 = bboxes[i][1] + bboxes[i][3]\n",
    "                    y1 = bboxes[i][0]\n",
    "                    y2 = bboxes[i][0] + bboxes[i][2]\n",
    "                    size = max(bboxes[i][2:3])\n",
    "                    \n",
    "                    im = Image.fromarray(gray[x1:x2, y1:y2])\n",
    "                    im_padded = Image.new(im.mode, (size, size), (255))\n",
    "                    if bboxes[i][2] > bboxes[i][3]:\n",
    "                        left = 0\n",
    "                        top = (size - bboxes[i][3]) //2\n",
    "                    else :\n",
    "                        top = 0\n",
    "                        left = (size - bboxes[i][2]) //2\n",
    "                        \n",
    "                    im_padded.paste(im, (left, top))\n",
    "                    im_padded.save(f\"{name}{n:05}-{i:05}.png\")\n",
    "                    stats = [name, n, i, bboxes[i][0] + bboxes[i][2]/2, bboxes[i][1] + bboxes[i][3]/2, bboxes[i][2], bboxes[i][3], area[i]]\n",
    "                    outwritter.writerow(stats)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_frame(q, config): ## TODO: write metadata file\n",
    "    \"\"\"\n",
    "    This function processes each frame (provided as cv2 image frame) for flatfielding and segmentation. The steps include\n",
    "    1. Flatfield intensities as indicated\n",
    "    2. Segment the image using cv2 MSER algorithmn.\n",
    "    3. Remove strongly overlapping bounding boxes\n",
    "    4. Save cropped targets.\n",
    "    \"\"\"\n",
    "\n",
    "    while True:\n",
    "        frame = q.get()\n",
    "        if config['general']['dry_run'] == 'True':\n",
    "            print('.')\n",
    "            return\n",
    "        \n",
    "        ## Read img and flatfield\n",
    "        gray = cv2.cvtColor(frame.read(), cv2.COLOR_BGR2GRAY)\n",
    "        gray = np.array(gray)\n",
    "        field = np.quantile(gray, q=float(config['segmentation']['flatfield_q']), axis=0)\n",
    "        gray = (gray / field.T * 255.0)\n",
    "        gray = gray.clip(0,255).astype(np.uint8)\n",
    "\n",
    "        # Apply Otsu's threshold\n",
    "        thresh = cv2.threshold(gray, 0, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)[1]\n",
    "        cnts = cv2.findContours(thresh, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "        cnts = cnts[0] if len(cnts) == 2 else cnts[1]\n",
    "\n",
    "        name = frame.get_name()\n",
    "        n = frame.get_n()\n",
    "        stats = []\n",
    "        with open(f'{name}statistics.csv', 'a', newline='\\n') as outcsv:\n",
    "            outwritter = csv.writer(outcsv, delimiter=',', quotechar='|')\n",
    "            for c in cnts:\n",
    "                x,y,w,h = cv2.boundingRect(c)\n",
    "                if w*h > int(config['segmentation']['min_area']):\n",
    "                    size = max(w, h)\n",
    "                    im = Image.fromarray(gray[y:(y+h), x:(x+w)])\n",
    "                    im_padded = Image.new(im.mode, (size, size), (255))\n",
    "                    \n",
    "                    if (w > h):\n",
    "                        left = 0\n",
    "                        top = (size - h)//2\n",
    "                    else:\n",
    "                        left = (size - w)//2\n",
    "                        top = 0\n",
    "                    im_padded.paste(im, (left, top))\n",
    "                    im_padded.save(f\"{name}{n:05}-{i:05}.png\")\n",
    "                    stats = [name, n, i, x + w/2, y + h/2, w, h, w*h]\n",
    "                    outwritter.writerow(stats)\n",
    "                    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_avi(avi_path, segmentation_dir, config, q):\n",
    "    \"\"\"\n",
    "    This function will take an avi filepath as input and perform the following steps:\n",
    "    1. Create output file structures/directories\n",
    "    2. Load each frame, pass it through flatfielding and sequentially save segmented targets\n",
    "    \"\"\"\n",
    "\n",
    "    # segmentation_dir: /media/plankline/Data/analysis/segmentation/Camera1/segmentation/Transect1-REG\n",
    "    _, filename = os.path.split(avi_path)\n",
    "    output_path = segmentation_dir + os.path.sep + filename + os.path.sep\n",
    "    os.makedirs(output_path, exist_ok=True)\n",
    "    \n",
    "    #con = sqlite3.connect(output_path + '/' + 'images.db')\n",
    "    #con.execute(\"CREATE TABLE frame(ID INT PRIMARY KEY NOT NULL,frame INT, crop INT, image BLOB)\")\n",
    "    #con.commit()\n",
    "    #con.close()\n",
    "\n",
    "    video = cv2.VideoCapture(avi_path)\n",
    "    #length = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    if not video.isOpened():\n",
    "        return\n",
    "    \n",
    "    with open(f'{output_path}statistics.csv', 'a', newline='\\n') as outcsv:\n",
    "        outwritter = csv.writer(outcsv, delimiter=',', quotechar='|')\n",
    "        outwritter.writerow(['file', 'frame', 'crop', 'x', 'y', 'w', 'h', 'area'])\n",
    "\n",
    "    n = 1\n",
    "    while True:\n",
    "        ret, frame = video.read()\n",
    "        if ret:\n",
    "            q.put(Frame(avi_path, output_path, frame, n), block = True)\n",
    "            n += 1\n",
    "        else:\n",
    "            break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Segmentation Script V2023.11.08\n"
     ]
    }
   ],
   "source": [
    "directory = '../../raw/camera1/GAK_202207/'\n",
    "\n",
    "config = {\n",
    "    'general' : {\n",
    "        'dir_permissions' : 511,\n",
    "        'dry_run' : 'False'\n",
    "    },\n",
    "    'segmentation' : {\n",
    "        'basename' : 'REG',\n",
    "        'min_area' : 200,\n",
    "        'flatfield_q' : 0.05\n",
    "    },\n",
    "    'classification' : {\n",
    "        'model_name' : 'Alpha',\n",
    "        'model_dir' : '../../model',\n",
    "        'scnn_instances' : 1,\n",
    "        'fast_scratch' : '/tmp',\n",
    "        'batchsize' : 64,\n",
    "        'image_size' : 128\n",
    "    },\n",
    "    'training' : {\n",
    "        'scnn_dir' : '../../training/20231002',\n",
    "        'model_name': 'Gamma',\n",
    "        'model_path': '../../model/',\n",
    "        'image_size': '128',\n",
    "        'start' : 10,\n",
    "        'stop' : 100,\n",
    "        'validationSetRatio' : 0.2,\n",
    "        'batchsize' : 16,\n",
    "        'seed': 123\n",
    "    }\n",
    "}\n",
    "\n",
    "v_string = \"V2023.11.08\"\n",
    "print(f\"Starting Segmentation Script {v_string}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup directories and find AVIs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Determine directories\n",
    "raw_dir = os.path.abspath(directory) # /media/plankline/Data/raw/Camera1/Transect1\n",
    "segmentation_dir = raw_dir.replace(\"raw\", \"analysis\") # /media/plankline/Data/analysis/Camera1/Transect1\n",
    "segmentation_dir = segmentation_dir.replace(\"camera0/\", \"camera0/segmentation/\") # /media/plankline/Data/analysis/Camera1/Transect1\n",
    "segmentation_dir = segmentation_dir.replace(\"camera1/\", \"camera1/segmentation/\") # /media/plankline/Data/analysis/Camera1/segmentation/Transect1\n",
    "segmentation_dir = segmentation_dir.replace(\"camera2/\", \"camera2/segmentation/\") # /media/plankline/Data/analysis/Camera1/segmentation/Transect1\n",
    "segmentation_dir = segmentation_dir.replace(\"camera3/\", \"camera3/segmentation/\") # /media/plankline/Data/analysis/Camera1/segmentation/Transect1\n",
    "    \n",
    "segmentation_dir = segmentation_dir + f\"-{config['segmentation']['basename']}\" # /media/plankline/Data/analysis/segmentation/Camera1/segmentation/Transect1-REG\n",
    "os.makedirs(segmentation_dir, int(config['general']['dir_permissions']), exist_ok = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of AVIs found: 1986\n"
     ]
    }
   ],
   "source": [
    "avis = []\n",
    "avis = [os.path.join(raw_dir, avi) for avi in os.listdir(raw_dir) if avi.endswith(\".avi\")]\n",
    "print(f\"Number of AVIs found: {len(avis)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Start workers and then process each AVI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "47\n"
     ]
    }
   ],
   "source": [
    "## Prepare workers for receiving frames\n",
    "num_threads = os.cpu_count() - 1\n",
    "#num_threads = 2\n",
    "max_queue = num_threads * 4\n",
    "q = Queue(maxsize=int(max_queue))\n",
    "\n",
    "for i in range(num_threads):\n",
    "    worker = Process(target=process_frame, args=(q, config,), daemon=True)\n",
    "    worker.start()\n",
    "    \n",
    "print(num_threads)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1986/1986 [20:31:40<00:00, 37.21s/it]   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Joining\n"
     ]
    }
   ],
   "source": [
    "for av in tqdm.tqdm(avis):\n",
    "    process_avi(av, segmentation_dir, config, q)\n",
    "\n",
    "print('Joining')\n",
    "worker.join(timeout=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
